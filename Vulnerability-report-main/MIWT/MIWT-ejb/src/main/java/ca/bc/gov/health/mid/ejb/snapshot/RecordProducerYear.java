package ca.bc.gov.health.mid.ejb.snapshot;

import ca.bc.gov.health.mid.ejb.entity.SnapshotRecord;
import java.sql.Connection;
import java.sql.PreparedStatement;
import java.sql.ResultSet;
import java.util.*;
import java.util.concurrent.BlockingQueue;
import java.util.concurrent.CountDownLatch;
import java.util.concurrent.TimeUnit;
import java.util.concurrent.atomic.AtomicInteger;
import java.util.logging.Level;
import java.util.logging.Logger;
import javax.sql.DataSource;

public class RecordProducerYear implements Runnable {

    private static final Logger logger = Logger.getLogger(RecordProducerYear.class.getName());

    private static final int CHUNK_SIZE = 1000;

    private DataSource dataSource;
    private BlockingQueue<List<SnapshotRecord>> records;
    private RecordValidator validator;

    private CountDownLatch latch;

    private AtomicInteger reads = new AtomicInteger();
    private Map<Long, Long> countPerHA = new HashMap<>();
    private Map<Long, Long> errorPerHA = new HashMap<>();

    private List<SnapshotRecord> chunk = new ArrayList<>(CHUNK_SIZE);

    public RecordProducerYear(DataSource dataSource, BlockingQueue<List<SnapshotRecord>> records, RecordValidator validator, CountDownLatch latch) {
        this.dataSource = dataSource;
        this.records = records;
        this.validator = validator;
        this.latch = latch;
    }

    @Override
    public void run() {
        try (Connection connection = dataSource.getConnection();
             PreparedStatement statement = connection.prepareStatement("SELECT * FROM MID_SNAPSHOT_YVW", ResultSet.TYPE_FORWARD_ONLY, ResultSet.CONCUR_READ_ONLY)) {
            statement.setFetchSize(CHUNK_SIZE);
            try (ResultSet resultSet = statement.executeQuery()) {
                while (resultSet.next()) {
                    SnapshotRecord record = new SnapshotRecord(resultSet);
                    Long ha = record.getHealthAuthorityId();
                    try {
                        if (validator.validate(record)) {
                            countPerHA.put(ha, countPerHA.getOrDefault(ha, 0L) + 1);
                            addRecord(record);
                        } else {
                            errorPerHA.put(ha, errorPerHA.getOrDefault(ha, 0L) + 1);
                        }
                    } catch (Exception exception) {
                        logger.log(Level.WARNING, "Error in exam " + record.getExamId(), exception);
                        errorPerHA.put(ha, errorPerHA.getOrDefault(ha, 0L) + 1);
                    }
                }
                putChunk(); // remaining records
                addDelimiter();
            }
        } catch (Exception exception) {
            logger.log(Level.SEVERE, "Unable to read from snapshot view.", exception);
            putChunk();
            addDelimiter();
        }
        latch.countDown();
    }

    private void addRecord(SnapshotRecord record) {
        chunk.add(record);
        reads.incrementAndGet();
        if (chunk.size() >= CHUNK_SIZE) {
            putChunk();
        }
    }

    private void putChunk() {
        try {
            if (records.offer(chunk, 30, TimeUnit.MINUTES)) {
                logger.log(Level.INFO, "Chunk {0} added to the queue.", chunk.hashCode());
                chunk = new ArrayList<>(CHUNK_SIZE);
            } else {
                logger.log(Level.WARNING, "Took too much time to submit a new chunk.");
            }
        } catch (InterruptedException exception) {
            Thread.currentThread().interrupt();
            logger.log(Level.SEVERE, "Interrupted while adding records chunk", exception);
        }
    }

    private void addDelimiter() {
        try {
            records.put(new ArrayList<>());
            logger.log(Level.INFO, "No record to read. Empty chunk added to the queue.");
        } catch (InterruptedException exception) {
            Thread.currentThread().interrupt();
            logger.log(Level.WARNING, "Interrupted while adding records chunk", exception);
        }
    }

    public int getReads() {
        return reads.get();
    }

    public Map<Long, Long> getCountPerHA() {
        return countPerHA;
    }

    public Map<Long, Long> getErrorPerHA() {
        return errorPerHA;
    }
}
